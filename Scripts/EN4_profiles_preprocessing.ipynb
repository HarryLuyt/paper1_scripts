{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "This script aims to select and subset EN4 profile data for comparing to HYCOM. The data is downloaded from: https://hadleyserver.metoffice.gov.uk/en4/download-en4-2-1.html and a description of the profile files can be found here: https://hadleyserver.metoffice.gov.uk/en4/en4-0-2-profile-file-format.html\n",
    "\n",
    "The files need to be prepared for ingesting by Bjorn's scripts to create station and depthlevels files (https://gitlab.com/backeb/hycom_enoi/-/blob/master/scripts/hycom/sandbox/make_hyc2station_infiles.py).\n",
    "\n",
    "The goal is to:\n",
    "1. first try subset the profiles to the model domain; then\n",
    "2. try export the required data into a .txt (or .csv) file for generating the station and depth files\n",
    "\n",
    "*Alternatively,* an attempt could be made to generate the files directly from the profiles netcdf files without first writing to a .txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harry/miniconda3/lib/python3.7/site-packages/xarray/core/merge.py:17: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import cartopy.crs as ccrs\n",
    "# import cartopy\n",
    "# from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import xarray as xr\n",
    "# from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.facecolor']='white'\n",
    "plt.rcParams['axes.facecolor']='white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe now need to import all the files, or a list thereof for sequential preprocessing\\nin a loop\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading a profile data file\n",
    "EN4_profile = xr.open_dataset('../Data/EN4_profiles/EN.4.2.1.f.profiles.g10.200901.nc')\n",
    "# ds_EN4 = ds_EN4.sel(time=slice('2009-01','2014-04'))\n",
    "# ds_EN4['temperature'] = ds_EN4['temperature'] - 273.15\n",
    "\n",
    "'''\n",
    "We now need to import all the files, or a list thereof for sequential preprocessing\n",
    "in a loop\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This converting to dataframe will need to take place within the loop that writes all\n",
    "data into a single file or variable.\n",
    "'''\n",
    "\n",
    "# convert the required fields to dataframe\n",
    "n_prof = EN4_profile['N_PROF'].to_dataframe()\n",
    "juld = EN4_profile['JULD'].to_dataframe()\n",
    "lat = EN4_profile['LATITUDE'].to_dataframe()\n",
    "lon = EN4_profile['LONGITUDE'].to_dataframe()\n",
    "sal = EN4_profile['PSAL_CORRECTED'].to_dataframe()\n",
    "temp = EN4_profile['TEMP'].to_dataframe()\n",
    "depth = EN4_profile['DEPH_CORRECTED'].to_dataframe()\n",
    "\n",
    "# subset the lats and lons to model domain\n",
    "lat_ind = np.where((lat <= -10) & (lat >= -50 ))[0]\n",
    "lat = lat.iloc[lat_ind]\n",
    "lon_ind = np.where((lon <= 70) & (lon >= 0))[0]\n",
    "lon = lon.iloc[lon_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join lats and lons for first dataset, 'tester'\n",
    "tester = lat.join(lon, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>DEPH_CORRECTED</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PSAL_CORRECTED</th>\n",
       "      <th>JULD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_PROF</th>\n",
       "      <th>N_LEVELS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">21</td>\n",
       "      <td>0</td>\n",
       "      <td>-43.943001</td>\n",
       "      <td>10.397</td>\n",
       "      <td>4.959837</td>\n",
       "      <td>7.933</td>\n",
       "      <td>34.209751</td>\n",
       "      <td>2009-01-01 13:34:46.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-43.943001</td>\n",
       "      <td>10.397</td>\n",
       "      <td>9.919554</td>\n",
       "      <td>7.851</td>\n",
       "      <td>34.218380</td>\n",
       "      <td>2009-01-01 13:34:46.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-43.943001</td>\n",
       "      <td>10.397</td>\n",
       "      <td>14.879150</td>\n",
       "      <td>7.834</td>\n",
       "      <td>34.221432</td>\n",
       "      <td>2009-01-01 13:34:46.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-43.943001</td>\n",
       "      <td>10.397</td>\n",
       "      <td>19.838627</td>\n",
       "      <td>7.814</td>\n",
       "      <td>34.225231</td>\n",
       "      <td>2009-01-01 13:34:46.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-43.943001</td>\n",
       "      <td>10.397</td>\n",
       "      <td>24.797983</td>\n",
       "      <td>7.698</td>\n",
       "      <td>34.236179</td>\n",
       "      <td>2009-01-01 13:34:46.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">32588</td>\n",
       "      <td>395</td>\n",
       "      <td>-29.983000</td>\n",
       "      <td>13.367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-01-31 22:39:00.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>-29.983000</td>\n",
       "      <td>13.367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-01-31 22:39:00.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>-29.983000</td>\n",
       "      <td>13.367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-01-31 22:39:00.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>-29.983000</td>\n",
       "      <td>13.367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-01-31 22:39:00.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>-29.983000</td>\n",
       "      <td>13.367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-01-31 22:39:00.000008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  LATITUDE  LONGITUDE  DEPH_CORRECTED   TEMP  PSAL_CORRECTED  \\\n",
       "N_PROF N_LEVELS                                                                \n",
       "21     0        -43.943001     10.397        4.959837  7.933       34.209751   \n",
       "       1        -43.943001     10.397        9.919554  7.851       34.218380   \n",
       "       2        -43.943001     10.397       14.879150  7.834       34.221432   \n",
       "       3        -43.943001     10.397       19.838627  7.814       34.225231   \n",
       "       4        -43.943001     10.397       24.797983  7.698       34.236179   \n",
       "...                    ...        ...             ...    ...             ...   \n",
       "32588  395      -29.983000     13.367             NaN    NaN             NaN   \n",
       "       396      -29.983000     13.367             NaN    NaN             NaN   \n",
       "       397      -29.983000     13.367             NaN    NaN             NaN   \n",
       "       398      -29.983000     13.367             NaN    NaN             NaN   \n",
       "       399      -29.983000     13.367             NaN    NaN             NaN   \n",
       "\n",
       "                                      JULD  \n",
       "N_PROF N_LEVELS                             \n",
       "21     0        2009-01-01 13:34:46.000017  \n",
       "       1        2009-01-01 13:34:46.000017  \n",
       "       2        2009-01-01 13:34:46.000017  \n",
       "       3        2009-01-01 13:34:46.000017  \n",
       "       4        2009-01-01 13:34:46.000017  \n",
       "...                                    ...  \n",
       "32588  395      2009-01-31 22:39:00.000008  \n",
       "       396      2009-01-31 22:39:00.000008  \n",
       "       397      2009-01-31 22:39:00.000008  \n",
       "       398      2009-01-31 22:39:00.000008  \n",
       "       399      2009-01-31 22:39:00.000008  \n",
       "\n",
       "[294000 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join other dataframes with inner join (Use intersection of keys from both frames)\n",
    "tester2 = tester.join(depth,how='inner').join(temp, how='inner').join(sal, how='inner').join(juld, how='inner')\n",
    "tester2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tester2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c326b3957505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create list of index values to be referenced later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtester2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtester2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tester2' is not defined"
     ]
    }
   ],
   "source": [
    "# Create list of index values to be referenced later\n",
    "tester2.index[0::400]\n",
    "lst = [i[0] for i in tester2.index[0::400]]\n",
    "lst[0]\n",
    "\n",
    "'''\n",
    "Hereafter, removal of NaN depths should be considered, then the building of the\n",
    "subsequent months of profile data should be done, too.\n",
    "The subsequent months should have unqiue station values, too, so the current thinking\n",
    "is to add len(N_PROF) to the next months N_PROF consecutively.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1876.2327"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing retrieval of max depth value\n",
    "tester2.loc[lst[0]]['DEPH_CORRECTED'].max()\n",
    "\n",
    "'''\n",
    "Here the max value can be retrieved, but the advantage of having each depth value\n",
    "in the final dataframe is that the entire depthvalues file can match the depth\n",
    "values from the profile, as opposed to Bjorn's 5 m incremental approach.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:                       (N_CALIB: 1, N_HISTORY: 0, N_LEVELS: 400, N_PARAM: 5, N_PROF: 32595)\n",
       "Dimensions without coordinates: N_CALIB, N_HISTORY, N_LEVELS, N_PARAM, N_PROF\n",
       "Data variables:\n",
       "    CALIBRATION_DATE              (N_PROF, N_CALIB, N_PARAM) |S14 b'' ... b''\n",
       "    CYCLE_NUMBER                  (N_PROF) int32 -2147483647 ... -2147483647\n",
       "    DATA_CENTRE                   (N_PROF) |S2 b'MO' b'MO' b'MO' ... b'MO' b'MO'\n",
       "    DATA_MODE                     (N_PROF) |S1 b'D' b'D' b'D' ... b'D' b'D' b'D'\n",
       "    DATA_STATE_INDICATOR          (N_PROF) |S4 b'2C+ ' b'2C+ ' ... b'2C+ '\n",
       "    DATA_TYPE                     |S16 b'ENSEMBLES EN3 v1'\n",
       "    DATE_CREATION                 |S14 b'20170421133031'\n",
       "    DATE_UPDATE                   |S14 b'20170421133031'\n",
       "    DC_REFERENCE                  (N_PROF) |S16 b' A20090101-02729' ... b' A20090131-65980'\n",
       "    DEPH_CORRECTED                (N_PROF, N_LEVELS) float32 4.3566914 ... nan\n",
       "    DEPH_CORRECTED_QC             (N_PROF, N_LEVELS) |S1 b'' b'' b'' ... b'' b''\n",
       "    DIRECTION                     (N_PROF) |S1 b'' b'' b'' b'' ... b'' b'' b''\n",
       "    FORMAT_VERSION                |S4 b'2.0'\n",
       "    HANDBOOK_VERSION              float32 1.0\n",
       "    HISTORY_ACTION                (N_HISTORY, N_PROF) |S4 \n",
       "    HISTORY_DATE                  (N_HISTORY, N_PROF) |S14 \n",
       "    HISTORY_INSTITUTION           (N_HISTORY, N_PROF) |S4 \n",
       "    HISTORY_PARAMETER             (N_HISTORY, N_PROF) |S4 \n",
       "    HISTORY_PREVIOUS_VALUE        (N_HISTORY, N_PROF) float32 \n",
       "    HISTORY_QCTEST                (N_HISTORY, N_PROF) |S16 \n",
       "    HISTORY_SOFTWARE              (N_HISTORY, N_PROF) |S4 \n",
       "    HISTORY_SOFTWARE_RELEASE      (N_HISTORY, N_PROF) |S4 \n",
       "    HISTORY_START_DEPH            (N_HISTORY, N_PROF) float32 \n",
       "    HISTORY_STOP_DEPH             (N_HISTORY, N_PROF) float32 \n",
       "    INST_REFERENCE                (N_PROF) |S64 b'                                                             846' ... b'                                                           22140'\n",
       "    JULD                          (N_PROF) datetime64[ns] 2009-01-01T23:43:08.000017 ... 2009-01-31T23:16:48.000017\n",
       "    JULD_LOCATION                 (N_PROF) datetime64[ns] 2009-01-01T23:43:08.000017 ... 2009-01-31T23:16:48.000017\n",
       "    JULD_QC                       (N_PROF) |S1 b'' b'' b'' b'' ... b'' b'' b''\n",
       "    LATITUDE                      (N_PROF) float64 -65.42 56.34 ... 21.9 -23.77\n",
       "    LONGITUDE                     (N_PROF) float64 -39.74 -17.4 ... -156.7 110.8\n",
       "    PARAMETER                     (N_PROF, N_CALIB, N_PARAM) |S4 b'    ' ... b'    '\n",
       "    PI_NAME                       (N_PROF) |S64 b'Simon Good, Met Office                                          ' ... b'Simon Good, Met Office                                          '\n",
       "    PLATFORM_NUMBER               (N_PROF) |S8 b'5901738 ' ... b'6299    '\n",
       "    POSITIONING_SYSTEM            (N_PROF) |S8 b'' b'' b'' b'' ... b'' b'' b''\n",
       "    POSITION_QC                   (N_PROF) |S1 b'1' b'1' b'1' ... b'1' b'1' b'1'\n",
       "    POTM_CORRECTED                (N_PROF, N_LEVELS) float32 -1.630088 ... nan\n",
       "    POTM_CORRECTED_QC             (N_PROF, N_LEVELS) |S1 b'1' b'1' ... b'0' b'0'\n",
       "    PROFILE_DEPH_QC               (N_PROF) |S1 b'' b'' b'' b'' ... b'' b'' b''\n",
       "    PROFILE_POTM_QC               (N_PROF) |S1 b'1' b'1' b'1' ... b'1' b'1' b'1'\n",
       "    PROFILE_PSAL_QC               (N_PROF) |S1 b'1' b'1' b'1' ... b'4' b'4' b'4'\n",
       "    PROJECT_NAME                  (N_PROF) |S64 b'ARGOD                                                           ' ... b'WOD09XBTCY    9699                                              '\n",
       "    PSAL_CORRECTED                (N_PROF, N_LEVELS) float32 34.104 ... nan\n",
       "    PSAL_CORRECTED_QC             (N_PROF, N_LEVELS) |S1 b'1' b'1' ... b'0' b'0'\n",
       "    QC_FLAGS_LEVELS               (N_PROF, N_LEVELS) int32 0 0 ... 33562627\n",
       "    QC_FLAGS_PROFILES             (N_PROF) int32 0 0 0 0 0 0 ... 0 0 0 0 0\n",
       "    REFERENCE_DATE_TIME           |S14 b'19500101000000'\n",
       "    SCIENTIFIC_CALIB_COEFFICIENT  (N_PROF, N_CALIB, N_PARAM) |S256 b'                                                                                                                                                                                                                                                                ' ... b'                                                                                                                                                                                                                                                                '\n",
       "    SCIENTIFIC_CALIB_COMMENT      (N_PROF, N_CALIB, N_PARAM) |S256 b'' ... b''\n",
       "    SCIENTIFIC_CALIB_EQUATION     (N_PROF, N_CALIB, N_PARAM) |S256 b'                                                                                                                                                                                                                                                                ' ... b'                                                                                                                                                                                                                                                                '\n",
       "    STATION_PARAMETERS            (N_PROF, N_PARAM) |S4 b'deph' ... b'bkps'\n",
       "    TEMP                          (N_PROF, N_LEVELS) float32 -1.63 ... nan\n",
       "    WMO_INST_TYPE                 (N_PROF) |S4 b' 831' b' 831' ... b' 401'\n",
       "    instrument_type               (N_PROF) object b'    ' b'    ' ... b't7db'\n",
       "    stretch_corrections           (N_PROF, N_LEVELS) float32 nan nan ... nan nan\n",
       "    thermal_corrections           (N_PROF) float32 nan nan ... -0.0119 -0.0119\n",
       "Attributes:\n",
       "    history:  Fri Apr 21 13:39:17 2017: /project/ukmo/rhel6/nco/bin/ncks -x -...\n",
       "    NCO:      4.3.2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EN4_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/EN4_profiles/EN.4.2.1.f.profiles.g10.200901.nc\n",
      "../Data/EN4_profiles/EN.4.2.1.f.profiles.g10.200902.nc\n"
     ]
    }
   ],
   "source": [
    "# Get list of profile netcdf files\n",
    "profiles = glob.glob('../Data/EN4_profiles/EN.4.2.1.f.profiles.g10.20090[12].nc')\n",
    "metadata = pd.DataFrame()\n",
    "total_profiles = 0\n",
    "profile_list = []\n",
    "\n",
    "for filename in profiles:\n",
    "    print(filename)\n",
    "    ds = xr.open_dataset(filename)\n",
    "    \n",
    "    # increment N_PROF by previous total to ensure unique IDs\n",
    "    ds['N_PROF']+=total_profiles\n",
    "    total_profiles = ds['N_PROF'][-1].values\n",
    "    \n",
    "    # convert the required fields to dataframes\n",
    "    n_prof = ds['N_PROF'].to_dataframe()\n",
    "    juld = ds['JULD'].to_dataframe()\n",
    "    lat = ds['LATITUDE'].to_dataframe()\n",
    "    lon = ds['LONGITUDE'].to_dataframe()\n",
    "    sal = ds['PSAL_CORRECTED'].to_dataframe()\n",
    "    temp = ds['TEMP'].to_dataframe()\n",
    "    depth = ds['DEPH_CORRECTED'].to_dataframe()\n",
    "\n",
    "    # subset the lats and lons to model domain\n",
    "    lat_ind = np.where((lat <= -10) & (lat >= -50 ))[0]\n",
    "    lat = lat.iloc[lat_ind]\n",
    "    lon_ind = np.where((lon <= 70) & (lon >= 0))[0]\n",
    "    lon = lon.iloc[lon_ind]\n",
    "    \n",
    "    # join dataframes with inner join (Use intersection of keys from both frames)\n",
    "    file_metadata = lat.join(lon, how='inner').join(depth,how='inner').join(temp, how='inner').join(sal, how='inner').join(juld, how='inner')\n",
    "    profile_list.extend([i[0] for i in file_metadata.index[0::400]])\n",
    "    file_metadata = file_metadata.dropna(subset=['DEPH_CORRECTED'])\n",
    "    metadata = metadata.append(file_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  78.440575,   82.9078  ,   88.06981 ,   92.53683 ,   97.301544,\n",
       "        102.36393 ,  106.9299  ,  111.69428 ,  121.12346 ,  130.5522  ,\n",
       "        140.57597 ,  150.2023  ,  159.332   ,  169.65204 ,  179.6739  ,\n",
       "        188.90152 ,  198.6248  ,  208.2484  ,  218.36758 ,  227.39507 ,\n",
       "        237.5133  ,  247.13509 ,  256.75644 ,  265.98056 ,  285.7169  ,\n",
       "        304.9555  ,  324.09317 ,  343.42734 ,  362.7597  ,  391.11057 ,\n",
       "        420.05215 ,  457.8089  ,  505.66382 ,  553.9039  ,  602.5287  ,\n",
       "        651.43915 ,  699.64526 ,  748.7307  ,  798.596   ,  847.1636  ,\n",
       "        895.7199  ,  945.35223 ,  994.0833  , 1043.1982  , 1092.104   ,\n",
       "       1141.591   , 1190.6714  , 1239.4441  , 1288.8962  , 1338.2382  ,\n",
       "       1387.3711  , 1436.1967  , 1534.9971  , 1632.963   , 1731.2773  ,\n",
       "       1829.2509  , 1926.9824  , 2024.3739  ], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.loc[profile_list[10]]['DEPH_CORRECTED'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Next step is to create the depthlevels files (completed; below) and the station files (to be completed) in the loop or in a new loop\n",
    "'''\n",
    "\n",
    "# depthlevels = np.arange(5, maxdepth[i], 5)\n",
    "# depthlevels = np.append(depthlevels, maxdepth[i])\n",
    "# f = open(\"DEPTHLEVEL_FILES/depthlevels.in.\"+str(stn[i])+\".\"+str(year[i])+\"_\"+str(\"%03d\" % (doy[i])), \"w\")\n",
    "# f.write(str(len(depthlevels))+\"                  # Number of z levels\"+\"\\n\")\n",
    "# for x in range(0, len(depthlevels)):\n",
    "# f.write(\"%s\\n\" % depthlevels[x])\n",
    "\n",
    "# f.close()\n",
    "\n",
    "stn = profile_list[10]\n",
    "date = pd.to_datetime(metadata.loc[profile_list[10]]['JULD'][0])\n",
    "doy = date.dayofyear - 1\n",
    "year = date.year\n",
    "\n",
    "depthlevels = metadata.loc[profile_list[10]]['DEPH_CORRECTED'].values\n",
    "f = open(\"depthlevels.in.\"+str(stn)+\".\"+str(year)+\"_\"+str(\"%03d\" % (doy)), \"w\")\n",
    "f.write(str(len(depthlevels))+\"                  # Number of z levels\"+\"\\n\")\n",
    "for depth in range(0, len(depthlevels)):\n",
    "    f.write(\"%s\\n\" % depthlevels[depth])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'N_PROF' (N_PROF: 36406)>\n",
       "array([36545, 36546, 36547, ..., 72948, 72949, 72950])\n",
       "Coordinates:\n",
       "  * N_PROF   (N_PROF) int64 36545 36546 36547 36548 ... 72947 72948 72949 72950"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['N_PROF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['N_PROF']+=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ds['N_PROF'][-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(36475)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
